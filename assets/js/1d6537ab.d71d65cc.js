"use strict";(self.webpackChunkacademy_robotic_sciences=self.webpackChunkacademy_robotic_sciences||[]).push([[2592],{4329:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>s,default:()=>h,frontMatter:()=>o,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"projects/lerobot-training/index","title":"LeRobot Training Project","description":"Master robotic learning with state-of-the-art imitation and reinforcement learning","source":"@site/docs/projects/lerobot-training/index.md","sourceDirName":"projects/lerobot-training","slug":"/projects/lerobot-training/","permalink":"/landing-page/docs/projects/lerobot-training/","draft":false,"unlisted":false,"editUrl":"https://github.com/academy-robotic-sciences/academy-robotic-sciences/tree/main/docs/projects/lerobot-training/index.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"index","title":"LeRobot Training Project","sidebar_position":1},"sidebar":"docsSidebar","previous":{"title":"SO-101 Arm Project","permalink":"/landing-page/docs/projects/so-101-arm/"},"next":{"title":"3D Prototyping Lab","permalink":"/landing-page/docs/projects/3d-prototyping/"}}');var t=i(4848),l=i(8453);const o={id:"index",title:"LeRobot Training Project",sidebar_position:1},s="LeRobot Training Project",a={},c=[{value:"Project Overview",id:"project-overview",level:2},{value:"What is LeRobot?",id:"what-is-lerobot",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Required Knowledge",id:"required-knowledge",level:3},{value:"Hardware Requirements",id:"hardware-requirements",level:3},{value:"Software Requirements",id:"software-requirements",level:3},{value:"Project Phases",id:"project-phases",level:2},{value:"Phase 1: Environment Setup (Week 1)",id:"phase-1-environment-setup-week-1",level:3},{value:"Phase 2: Data Collection (Week 2-3)",id:"phase-2-data-collection-week-2-3",level:3},{value:"Phase 3: Model Training (Week 4-5)",id:"phase-3-model-training-week-4-5",level:3},{value:"Phase 4: Deployment (Week 6-7)",id:"phase-4-deployment-week-6-7",level:3},{value:"Phase 5: Advanced Topics (Week 8+)",id:"phase-5-advanced-topics-week-8",level:3},{value:"Installation Guide",id:"installation-guide",level:2},{value:"Step 1: Install LeRobot",id:"step-1-install-lerobot",level:3},{value:"Step 2: Set Up Robot Interface",id:"step-2-set-up-robot-interface",level:3},{value:"Core Tasks",id:"core-tasks",level:2},{value:"Task 1: Pick and Place",id:"task-1-pick-and-place",level:3},{value:"Task 2: Stacking",id:"task-2-stacking",level:3},{value:"Task 3: Tool Use",id:"task-3-tool-use",level:3},{value:"Data Collection Strategies",id:"data-collection-strategies",level:2},{value:"Teleoperation Setup",id:"teleoperation-setup",level:3},{value:"Kinesthetic Teaching",id:"kinesthetic-teaching",level:3},{value:"Model Architectures",id:"model-architectures",level:2},{value:"Behavior Cloning",id:"behavior-cloning",level:3},{value:"Transformer Policy",id:"transformer-policy",level:3},{value:"Diffusion Policy",id:"diffusion-policy",level:3},{value:"Training Best Practices",id:"training-best-practices",level:2},{value:"Data Augmentation",id:"data-augmentation",level:3},{value:"Hyperparameter Tuning",id:"hyperparameter-tuning",level:3},{value:"Evaluation Metrics",id:"evaluation-metrics",level:2},{value:"Success Rate",id:"success-rate",level:3},{value:"Trajectory Similarity",id:"trajectory-similarity",level:3},{value:"Sim-to-Real Transfer",id:"sim-to-real-transfer",level:2},{value:"Domain Randomization",id:"domain-randomization",level:3},{value:"System Identification",id:"system-identification",level:3},{value:"Debugging &amp; Troubleshooting",id:"debugging--troubleshooting",level:2},{value:"Common Issues",id:"common-issues",level:3},{value:"Visualization Tools",id:"visualization-tools",level:3},{value:"Advanced Topics",id:"advanced-topics",level:2},{value:"Multi-Task Learning",id:"multi-task-learning",level:3},{value:"Meta-Learning",id:"meta-learning",level:3},{value:"Project Deliverables",id:"project-deliverables",level:2},{value:"Required Submissions",id:"required-submissions",level:3},{value:"Evaluation Criteria",id:"evaluation-criteria",level:3},{value:"Resources",id:"resources",level:2},{value:"Documentation",id:"documentation",level:3},{value:"Datasets",id:"datasets",level:3},{value:"Community",id:"community",level:3},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"lerobot-training-project",children:"LeRobot Training Project"})}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Master robotic learning with state-of-the-art imitation and reinforcement learning"})}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"project-overview",children:"Project Overview"}),"\n",(0,t.jsx)(n.p,{children:"The LeRobot Training project teaches you to train robots using modern machine learning techniques. Using the LeRobot framework, you'll collect demonstrations, train policies, and deploy them on real hardware - bridging the gap between AI research and practical robotics."}),"\n",(0,t.jsx)(n.h2,{id:"what-is-lerobot",children:"What is LeRobot?"}),"\n",(0,t.jsx)(n.p,{children:"LeRobot is an open-source framework for:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Data Collection"}),": Record expert demonstrations"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Model Training"}),": Imitation and reinforcement learning"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sim-to-Real"}),": Transfer learning to real robots"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Deployment"}),": Run policies on actual hardware"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(n.p,{children:"By completing this project, you'll:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Understand imitation learning principles"}),"\n",(0,t.jsx)(n.li,{children:"Master data collection techniques"}),"\n",(0,t.jsx)(n.li,{children:"Train and evaluate ML models"}),"\n",(0,t.jsx)(n.li,{children:"Deploy AI on real robots"}),"\n",(0,t.jsx)(n.li,{children:"Debug learning systems"}),"\n",(0,t.jsx)(n.li,{children:"Optimize performance"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,t.jsx)(n.h3,{id:"required-knowledge",children:"Required Knowledge"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Python programming"}),"\n",(0,t.jsx)(n.li,{children:"Basic machine learning concepts"}),"\n",(0,t.jsx)(n.li,{children:"Linear algebra fundamentals"}),"\n",(0,t.jsx)(n.li,{children:"ROS2 basics (helpful)"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"hardware-requirements",children:"Hardware Requirements"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Option 1"}),": SO-101 arm (recommended)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Option 2"}),": Any ROS2-compatible robot"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Option 3"}),": Simulation only (limited learning)"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"software-requirements",children:"Software Requirements"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Ubuntu 22.04 LTS"}),"\n",(0,t.jsx)(n.li,{children:"Python 3.10+"}),"\n",(0,t.jsx)(n.li,{children:"PyTorch 2.0+"}),"\n",(0,t.jsx)(n.li,{children:"CUDA 11.7+ (for GPU)"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"project-phases",children:"Project Phases"}),"\n",(0,t.jsx)(n.h3,{id:"phase-1-environment-setup-week-1",children:"Phase 1: Environment Setup (Week 1)"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Install LeRobot framework"}),"\n",(0,t.jsx)(n.li,{children:"Set up simulation environment"}),"\n",(0,t.jsx)(n.li,{children:"Configure hardware interface"}),"\n",(0,t.jsx)(n.li,{children:"Test data collection pipeline"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"phase-2-data-collection-week-2-3",children:"Phase 2: Data Collection (Week 2-3)"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Record expert demonstrations"}),"\n",(0,t.jsx)(n.li,{children:"Implement teleoperation"}),"\n",(0,t.jsx)(n.li,{children:"Augment dataset"}),"\n",(0,t.jsx)(n.li,{children:"Validate data quality"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"phase-3-model-training-week-4-5",children:"Phase 3: Model Training (Week 4-5)"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Train behavior cloning model"}),"\n",(0,t.jsx)(n.li,{children:"Implement DAgger"}),"\n",(0,t.jsx)(n.li,{children:"Fine-tune hyperparameters"}),"\n",(0,t.jsx)(n.li,{children:"Evaluate performance"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"phase-4-deployment-week-6-7",children:"Phase 4: Deployment (Week 6-7)"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Deploy to simulation"}),"\n",(0,t.jsx)(n.li,{children:"Transfer to real robot"}),"\n",(0,t.jsx)(n.li,{children:"Handle edge cases"}),"\n",(0,t.jsx)(n.li,{children:"Optimize inference"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"phase-5-advanced-topics-week-8",children:"Phase 5: Advanced Topics (Week 8+)"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Multi-task learning"}),"\n",(0,t.jsx)(n.li,{children:"Sim-to-real transfer"}),"\n",(0,t.jsx)(n.li,{children:"Online learning"}),"\n",(0,t.jsx)(n.li,{children:"Custom architectures"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"installation-guide",children:"Installation Guide"}),"\n",(0,t.jsx)(n.h3,{id:"step-1-install-lerobot",children:"Step 1: Install LeRobot"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'# Create conda environment\nconda create -n lerobot python=3.10\nconda activate lerobot\n\n# Install PyTorch with CUDA\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n\n# Install LeRobot\npip install lerobot\n\n# Verify installation\npython -c "import lerobot; print(lerobot.__version__)"\n'})}),"\n",(0,t.jsx)(n.h3,{id:"step-2-set-up-robot-interface",children:"Step 2: Set Up Robot Interface"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Clone robot interface\ngit clone https://github.com/robot-campus/lerobot-so101\ncd lerobot-so101\n\n# Install dependencies\npip install -r requirements.txt\n\n# Configure robot\npython setup_robot.py --robot so101\n"})}),"\n",(0,t.jsx)(n.h2,{id:"core-tasks",children:"Core Tasks"}),"\n",(0,t.jsx)(n.h3,{id:"task-1-pick-and-place",children:"Task 1: Pick and Place"}),"\n",(0,t.jsx)(n.p,{children:"Train a robot to pick and place objects:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from lerobot.envs import PickPlaceEnv\nfrom lerobot.collectors import TeleoperationCollector\n\n# Initialize environment\nenv = PickPlaceEnv(render=True)\ncollector = TeleoperationCollector(env)\n\n# Collect demonstrations\nfor episode in range(50):\n    print(f"Collecting episode {episode}")\n    trajectory = collector.collect_episode()\n    collector.save(f"demos/pickplace_{episode}.pkl")\n'})}),"\n",(0,t.jsx)(n.h3,{id:"task-2-stacking",children:"Task 2: Stacking"}),"\n",(0,t.jsx)(n.p,{children:"Teach precise stacking behavior:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from lerobot.tasks import StackingTask\nfrom lerobot.models import BehaviorCloning\n\n# Load demonstrations\ndataset = StackingDataset("demos/stacking/")\n\n# Train model\nmodel = BehaviorCloning(\n    obs_dim=env.observation_space.shape,\n    action_dim=env.action_space.shape,\n    hidden_dims=[256, 256]\n)\n\ntrainer = Trainer(\n    model=model,\n    dataset=dataset,\n    batch_size=32,\n    learning_rate=1e-4\n)\n\ntrainer.train(epochs=100)\n'})}),"\n",(0,t.jsx)(n.h3,{id:"task-3-tool-use",children:"Task 3: Tool Use"}),"\n",(0,t.jsx)(n.p,{children:"Advanced manipulation with tools:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from lerobot.policies import DiffusionPolicy\n\n# Initialize diffusion policy\npolicy = DiffusionPolicy(\n    observation_dim=45,\n    action_dim=7,\n    diffusion_steps=100\n)\n\n# Train with demonstrations\npolicy.train(\n    demonstrations="demos/tool_use/",\n    val_split=0.1,\n    epochs=200\n)\n\n# Deploy policy\nwhile True:\n    obs = env.get_observation()\n    action = policy.predict(obs)\n    env.step(action)\n'})}),"\n",(0,t.jsx)(n.h2,{id:"data-collection-strategies",children:"Data Collection Strategies"}),"\n",(0,t.jsx)(n.h3,{id:"teleoperation-setup",children:"Teleoperation Setup"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from lerobot.teleop import SpaceMouse, KeyboardTeleop\n\n# Option 1: SpaceMouse (recommended)\nteleop = SpaceMouse()\n\n# Option 2: Keyboard\nteleop = KeyboardTeleop()\n\n# Collect data\nenv = RobotEnv()\ncollector = DataCollector(env, teleop)\n\nfor i in range(100):\n    trajectory = collector.collect_trajectory()\n    save_trajectory(trajectory, f"demo_{i}.pkl")\n'})}),"\n",(0,t.jsx)(n.h3,{id:"kinesthetic-teaching",children:"Kinesthetic Teaching"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from lerobot.teaching import KinestheticTeacher\n\nteacher = KinestheticTeacher(robot)\nteacher.enable_gravity_compensation()\n\nprint("Move the robot to demonstrate...")\ntrajectory = teacher.record_demonstration()\nteacher.save(trajectory)\n'})}),"\n",(0,t.jsx)(n.h2,{id:"model-architectures",children:"Model Architectures"}),"\n",(0,t.jsx)(n.h3,{id:"behavior-cloning",children:"Behavior Cloning"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"class BCModel(nn.Module):\n    def __init__(self, obs_dim, action_dim):\n        super().__init__()\n        self.mlp = nn.Sequential(\n            nn.Linear(obs_dim, 256),\n            nn.ReLU(),\n            nn.Linear(256, 256),\n            nn.ReLU(),\n            nn.Linear(256, action_dim)\n        )\n\n    def forward(self, obs):\n        return self.mlp(obs)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"transformer-policy",children:"Transformer Policy"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from lerobot.models import TransformerPolicy\n\npolicy = TransformerPolicy(\n    obs_dim=50,\n    action_dim=7,\n    context_length=10,\n    n_heads=8,\n    n_layers=4\n)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"diffusion-policy",children:"Diffusion Policy"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from lerobot.models import DiffusionPolicy\n\npolicy = DiffusionPolicy(\n    obs_dim=50,\n    action_dim=7,\n    diffusion_steps=100,\n    model_type='unet'\n)\n"})}),"\n",(0,t.jsx)(n.h2,{id:"training-best-practices",children:"Training Best Practices"}),"\n",(0,t.jsx)(n.h3,{id:"data-augmentation",children:"Data Augmentation"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from lerobot.augmentation import RandomCrop, ColorJitter\n\naugmentations = [\n    RandomCrop(size=224),\n    ColorJitter(brightness=0.2),\n    GaussianNoise(std=0.01)\n]\n\ndataset = AugmentedDataset(\n    base_dataset,\n    augmentations=augmentations\n)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"hyperparameter-tuning",children:"Hyperparameter Tuning"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from lerobot.tuning import GridSearch\n\nparam_grid = {\n    'learning_rate': [1e-3, 1e-4, 1e-5],\n    'batch_size': [16, 32, 64],\n    'hidden_dims': [[256, 256], [512, 512]]\n}\n\nbest_params = GridSearch(\n    model_class=BCModel,\n    param_grid=param_grid,\n    dataset=dataset,\n    n_trials=20\n)\n"})}),"\n",(0,t.jsx)(n.h2,{id:"evaluation-metrics",children:"Evaluation Metrics"}),"\n",(0,t.jsx)(n.h3,{id:"success-rate",children:"Success Rate"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"def evaluate_policy(policy, env, n_episodes=100):\n    successes = 0\n    for _ in range(n_episodes):\n        obs = env.reset()\n        for _ in range(env.max_steps):\n            action = policy(obs)\n            obs, reward, done, info = env.step(action)\n            if done:\n                successes += info['success']\n                break\n    return successes / n_episodes\n"})}),"\n",(0,t.jsx)(n.h3,{id:"trajectory-similarity",children:"Trajectory Similarity"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from lerobot.metrics import trajectory_similarity\n\nsimilarity = trajectory_similarity(\n    expert_trajectories,\n    policy_trajectories,\n    metric='dtw'  # Dynamic Time Warping\n)\n"})}),"\n",(0,t.jsx)(n.h2,{id:"sim-to-real-transfer",children:"Sim-to-Real Transfer"}),"\n",(0,t.jsx)(n.h3,{id:"domain-randomization",children:"Domain Randomization"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from lerobot.sim2real import DomainRandomizer\n\nrandomizer = DomainRandomizer(\n    friction_range=(0.5, 1.5),\n    mass_range=(0.8, 1.2),\n    color_range=(0.8, 1.2),\n    camera_range=(-5, 5)\n)\n\nenv = randomizer.wrap(base_env)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"system-identification",children:"System Identification"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from lerobot.sim2real import SystemIdentification\n\n# Collect real robot data\nreal_data = collect_real_trajectories(n=10)\n\n# Optimize sim parameters\nsim_params = SystemIdentification.optimize(\n    sim_env,\n    real_data,\n    parameters=['friction', 'damping', 'masses']\n)\n"})}),"\n",(0,t.jsx)(n.h2,{id:"debugging--troubleshooting",children:"Debugging & Troubleshooting"}),"\n",(0,t.jsx)(n.h3,{id:"common-issues",children:"Common Issues"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Low Success Rate"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Collect more diverse demonstrations"}),"\n",(0,t.jsx)(n.li,{children:"Check data quality"}),"\n",(0,t.jsx)(n.li,{children:"Increase model capacity"}),"\n",(0,t.jsx)(n.li,{children:"Tune hyperparameters"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Sim-to-Real Gap"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Add domain randomization"}),"\n",(0,t.jsx)(n.li,{children:"Collect real robot data"}),"\n",(0,t.jsx)(n.li,{children:"Fine-tune on hardware"}),"\n",(0,t.jsx)(n.li,{children:"Reduce observation noise"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Slow Training"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Use GPU acceleration"}),"\n",(0,t.jsx)(n.li,{children:"Reduce batch size"}),"\n",(0,t.jsx)(n.li,{children:"Implement gradient accumulation"}),"\n",(0,t.jsx)(n.li,{children:"Use mixed precision"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"visualization-tools",children:"Visualization Tools"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from lerobot.visualization import plot_trajectory, plot_loss\n\n# Visualize trajectories\nplot_trajectory(expert_traj, label='Expert')\nplot_trajectory(policy_traj, label='Policy')\n\n# Monitor training\nplot_loss(train_losses, val_losses)\n"})}),"\n",(0,t.jsx)(n.h2,{id:"advanced-topics",children:"Advanced Topics"}),"\n",(0,t.jsx)(n.h3,{id:"multi-task-learning",children:"Multi-Task Learning"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from lerobot.multitask import MultiTaskPolicy\n\ntasks = ['pick', 'place', 'stack', 'push']\npolicy = MultiTaskPolicy(tasks)\n\nfor task in tasks:\n    dataset = load_dataset(task)\n    policy.train_task(task, dataset)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"meta-learning",children:"Meta-Learning"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from lerobot.meta import MAML\n\nmeta_learner = MAML(\n    model=policy,\n    inner_lr=0.01,\n    outer_lr=0.001\n)\n\nmeta_learner.train(task_distributions)\n"})}),"\n",(0,t.jsx)(n.h2,{id:"project-deliverables",children:"Project Deliverables"}),"\n",(0,t.jsx)(n.h3,{id:"required-submissions",children:"Required Submissions"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Trained Model"}),": Checkpoint files"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Demo Video"}),": 3-minute showcase"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Technical Report"}),": Methods and results"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Code Repository"}),": Clean, documented code"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Dataset"}),": Collected demonstrations"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"evaluation-criteria",children:"Evaluation Criteria"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Task success rate (40%)"}),"\n",(0,t.jsx)(n.li,{children:"Code quality (20%)"}),"\n",(0,t.jsx)(n.li,{children:"Documentation (20%)"}),"\n",(0,t.jsx)(n.li,{children:"Innovation (10%)"}),"\n",(0,t.jsx)(n.li,{children:"Presentation (10%)"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"resources",children:"Resources"}),"\n",(0,t.jsx)(n.h3,{id:"documentation",children:"Documentation"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://lerobot.ai/docs",children:"LeRobot Official Docs"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://pytorch.org/tutorials",children:"PyTorch Tutorials"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://github.com/robot-campus/papers",children:"Robot Learning Papers"})}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"datasets",children:"Datasets"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"LeRobot Dataset Hub"}),"\n",(0,t.jsx)(n.li,{children:"Open X-Embodiment"}),"\n",(0,t.jsx)(n.li,{children:"RoboNet"}),"\n",(0,t.jsx)(n.li,{children:"Custom SO-101 datasets"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"community",children:"Community"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Discord: #lerobot-training"}),"\n",(0,t.jsx)(n.li,{children:"Weekly paper reading group"}),"\n",(0,t.jsx)(n.li,{children:"Model sharing hub"}),"\n",(0,t.jsx)(n.li,{children:"Debugging sessions"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,t.jsx)(n.p,{children:"After completing this project:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Specialize"}),": Focus on specific algorithms"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Research"}),": Implement latest papers"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Contribute"}),": Add to LeRobot framework"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Compete"}),": Join robotics competitions"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Innovate"}),": Develop novel methods"]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsxs)(n.p,{children:["Ready to train intelligent robots? ",(0,t.jsx)(n.a,{href:"/docs/projects/lerobot-training/setup",children:"Start with environment setup \u2192"})]})]})}function h(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>s});var r=i(6540);const t={},l=r.createContext(t);function o(e){const n=r.useContext(l);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),r.createElement(l.Provider,{value:n},e.children)}}}]);